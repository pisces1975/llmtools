{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from urllib.parse import urlencode\n",
    "from utilities import logger\n",
    "import mysql.connector\n",
    "#from utilities import ConfigReader\n",
    "from utilities.sha_tools import generate_sha_digest\n",
    "from sqlalchemy import Column, Integer, String, Text, Date\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "api_user = 'h=Czxr?m'\n",
    "\n",
    "api_password = 'B537AF1C-64F9-FB2D-DC31-1E8C334E8D79'\n",
    "mylogger = logger.Logger(name='TAPD_ana', debug=True).logger\n",
    "\n",
    "def html_to_text(html):\n",
    "    if not html or len(html) == 0:\n",
    "        return ''\n",
    "    \n",
    "    #\"抛弃HTML标签，只提取所有文本内容\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-25 00:05:32.123\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[34m\u001b[1mDatabase connection successful. Result: 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 创建基础类\n",
    "Base = declarative_base()\n",
    "\n",
    "username = 'root'\n",
    "password = 'newpass'\n",
    "#host = \"127.0.0.1\"\n",
    "host = '10.101.9.50'\n",
    "dbname = 'requirements'\n",
    "engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}/{dbname}\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "local_session = Session()\n",
    "\n",
    "try:\n",
    "    # 连接数据库，并执行一个简单查询\n",
    "    connection = engine.connect()\n",
    "    result = connection.execute(\"SELECT 1\")\n",
    "    \n",
    "    # 打印结果\n",
    "    mylogger.debug(f\"Database connection successful. Result: {result.scalar()}\")\n",
    "    \n",
    "    # 不要忘记关闭连接！\n",
    "    connection.close()\n",
    "    \n",
    "except Exception as e:\n",
    "    mylogger.error(f\"Database connection failed. Error: {e}\")\n",
    "\n",
    "class Project(Base):\n",
    "    __tablename__ = 'project_info'\n",
    "\n",
    "    workspace_id = Column(String(255), primary_key=True)\n",
    "    name = Column(String(255))\n",
    "    systems = Column(String(255))\n",
    "    modify_time = Column(Date)\n",
    "    extension1 = Column(String(255))\n",
    "    url = Column(String(255))\n",
    "    \n",
    "class BaseStory(Base):\n",
    "    __tablename__ = 'base_stories'\n",
    "    __abstract__ = True\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    workspace_id = Column(String(255))\n",
    "    story_id = Column(String(255))\n",
    "    name = Column(String(512))\n",
    "    description = Column(Text)\n",
    "    url = Column(String(255))\n",
    "    status = Column(String(255))\n",
    "    developer = Column(String(255))\n",
    "    creator = Column(String(255))\n",
    "    finger_print = Column(String(255))\n",
    "    extension1 = Column(String(255))\n",
    "    extension2 = Column(String(255))\n",
    "    extension3 = Column(String(255))\n",
    "    extension4 = Column(String(255))\n",
    "    content = Column(Text)\n",
    "    vector_id = Column(Integer)\n",
    "    modify_time = Column(Date)\n",
    "    close_time = Column(Date)\n",
    "class Story(BaseStory):\n",
    "    __tablename__ = 'stories'    \n",
    "\n",
    "\n",
    "class BPStory(BaseStory):\n",
    "    __tablename__ = 'stories_bp' \n",
    "    customer = Column(String(255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "data = pd.read_excel('project-0129.xlsx')\n",
    "\n",
    "# admin info is added in \"项目信息.xlsx\"，this function is not longer used\n",
    "def update_admin():\n",
    "        for _, row in data.iterrows():\n",
    "                project_record = local_session.query(Project).filter_by(workspace_id=row['workspace_id']).first()\n",
    "\n",
    "                # 更新extension字段\n",
    "                if project_record:\n",
    "                        project_record.extension1 = row['管理员']\n",
    "                        local_session.commit()\n",
    "                        print(f\"Record with workspace_id '{project_record.workspace_id}' updated successfully.\")\n",
    "                else:\n",
    "                        print(f\"Record with workspace_id 'your_workspace_id' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from sqlalchemy import create_engine, Table, MetaData\n",
    "#from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "current_date = current_datetime.date()\n",
    "\n",
    "# 使用pandas读取excel文件\n",
    "data = pd.read_excel('项目信息.xls')\n",
    "\n",
    "execute_add_flag = True\n",
    "\n",
    "# 遍历数据行并插入到数据库表中\n",
    "for _, row in data.iterrows():\n",
    "    if not local_session.query(Project).filter_by(workspace_id=row['workspace_id']).first():  \n",
    "        mylogger.debug(f\"need to add project {row['name']}\")      \n",
    "        if execute_add_flag:\n",
    "                record={'workspace_id':row['workspace_id'], \n",
    "                        'name':row['name'], \n",
    "                        'systems':row['systems'], \n",
    "                        'modify_time':current_date, \n",
    "                        'url':f\"https://www.tapd.cn/{row['workspace_id']}\",\n",
    "                        'extension1':row['admin']}\n",
    "                project = Project(**record)\n",
    "                local_session.add(project)  \n",
    "\n",
    "# 提交会话\n",
    "if execute_add_flag:\n",
    "      local_session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-24 22:46:52.747\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1m5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 查询所有的workspace_id\n",
    "workspace_ids = local_session.query(Project.workspace_id).all()\n",
    "# 将结果转为列表\n",
    "workspace_id_list = [id[0] for id in workspace_ids]\n",
    "\n",
    "\n",
    "wid_already_in = local_session.query(Story.workspace_id).distinct().all()\n",
    "wid_already_in_list = [id[0] for id in wid_already_in]\n",
    "wid_already_in_list.append('62366085') # BP，单独存储\n",
    "wid_already_in_list.append('39451937') # 星票通，单独存储\n",
    "wid_already_in_list.append('54057645') #雅迪，没有需求\n",
    "new_ids = set(workspace_id_list).difference(set(wid_already_in_list))\n",
    "mylogger.debug(len(new_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_table = '../stories'\n",
    "def isBP():\n",
    "    if 'bp' in story_table:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "isBP()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def insert_data(session, record):\n",
    "    story = None\n",
    "    if isBP():\n",
    "        if not session.query(BPStory).filter_by(story_id=record['story_id']).first():\n",
    "            story = BPStory(**record)\n",
    "    else:\n",
    "        if not session.query(Story).filter_by(story_id=record['story_id']).first():\n",
    "            story = Story(**record)\n",
    "    if story:\n",
    "        session.add(story)\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def update_story_db(items):\n",
    "    total = len(items)\n",
    "    for story in tqdm(items, total=total):\n",
    "        # if story['workspace_id'] not in complete_wid:\n",
    "        #     continue\n",
    "        record = {}\n",
    "        record['workspace_id'] = story['workspace_id']\n",
    "        record['story_id'] = story['id']\n",
    "        record['name'] = story['name']\n",
    "        record['creator'] = story['creator']\n",
    "        record['status'] = story['status']\n",
    "        record['developer'] = story['developer']\n",
    "        if story['description']: \n",
    "            record['description'] = story['description'][:3000] \n",
    "        else: \n",
    "            record['description'] = ''\n",
    "        record['url'] = f\"https://www.tapd.cn/{record['workspace_id']}/prong/stories/view/{record['story_id']}\"\n",
    "        record['content'] = html_to_text(record['description'])\n",
    "        record['finger_print'] = generate_sha_digest(record['content'])\n",
    "        record['modify_time'] = story['modified']\n",
    "        if story['completed']:\n",
    "            record['close_time'] = story['completed']\n",
    "        else:\n",
    "            record['close_time'] = '2100-01-01'\n",
    "        \n",
    "        if isBP():        \n",
    "            record['customer'] = story['custom_field_one']\n",
    "        \n",
    "        insert_data(local_session, record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids=['66563110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-24 23:05:22.300\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[34m\u001b[1m1/1 Start to process 66563110 国家电投 3335 entries\u001b[0m\n",
      "\u001b[32m2024-03-24 23:05:22.302\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #1\u001b[0m\n",
      "\u001b[32m2024-03-24 23:06:03.344\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #2\u001b[0m\n",
      "\u001b[32m2024-03-24 23:06:42.618\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #3\u001b[0m\n",
      "\u001b[32m2024-03-24 23:07:22.087\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #4\u001b[0m\n",
      "\u001b[32m2024-03-24 23:08:01.914\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #5\u001b[0m\n",
      "\u001b[32m2024-03-24 23:08:41.161\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #6\u001b[0m\n",
      "\u001b[32m2024-03-24 23:09:20.925\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #7\u001b[0m\n",
      "\u001b[32m2024-03-24 23:10:01.632\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #8\u001b[0m\n",
      "\u001b[32m2024-03-24 23:10:42.874\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #9\u001b[0m\n",
      "\u001b[32m2024-03-24 23:11:43.219\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #10\u001b[0m\n",
      "\u001b[32m2024-03-24 23:12:23.350\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #11\u001b[0m\n",
      "\u001b[32m2024-03-24 23:13:03.212\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #12\u001b[0m\n",
      "\u001b[32m2024-03-24 23:13:43.427\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #13\u001b[0m\n",
      "\u001b[32m2024-03-24 23:14:23.137\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #14\u001b[0m\n",
      "\u001b[32m2024-03-24 23:15:03.275\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #15\u001b[0m\n",
      "\u001b[32m2024-03-24 23:15:43.276\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #16\u001b[0m\n",
      "\u001b[32m2024-03-24 23:16:24.900\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #17\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2681/3335 [07:14<02:41,  4.05it/s]C:\\Users\\NstcUser\\AppData\\Local\\Temp\\ipykernel_16808\\1660417174.py:26: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html, \"html.parser\")\n",
      "100%|██████████| 3335/3335 [09:36<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-24 23:26:33.092\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m93\u001b[0m - \u001b[34m\u001b[1mtotal entries = 3335\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "base_url = \"https://api.tapd.cn/stories\"\n",
    "page_to_break = 0\n",
    "item_list_original = []\n",
    "item_to_update = []\n",
    "item_to_analyze = []\n",
    "complete_wid = set()\n",
    "i = 1\n",
    "\n",
    "for wid in new_ids:    \n",
    "    try:\n",
    "        r = requests.get(f\"https://api.tapd.cn/stories/count?workspace_id={wid}\", auth=(api_user, api_password))\n",
    "        ret = r.text # 获取接口返回结果\n",
    "        # print(ret) # Python 3\n",
    "        json_string = json.loads(ret)\n",
    "        total_entries = json_string['data']['count']\n",
    "        pinfo = local_session.query(Project.name).filter(Project.workspace_id == wid).first()\n",
    "        prj_name = pinfo[0]\n",
    "        # mylogger.info(f'{wid} {prj_name}, {total_entries}')\n",
    "        sum += total_entries\n",
    "    except Exception as e:\n",
    "        mylogger.error(f\"{wid} {prj_name} Something goes wrong {e}\")    \n",
    "        continue\n",
    "\n",
    "    current_page = 1    \n",
    "    if total_entries >= 1000:\n",
    "        batch_size = 200\n",
    "    else:\n",
    "        batch_size =100\n",
    "    current_index = 0\n",
    "    item_number = 0    \n",
    "\n",
    "    current_batch = []\n",
    "    mylogger.debug(f\"{i}/{len(new_ids)} Start to process {wid} {prj_name} {total_entries} entries\")\n",
    "    while current_index < total_entries:\n",
    "        mylogger.debug(f\">>>>>>>>>>Fetch page #{current_page}\")\n",
    "        params = {\n",
    "            \"workspace_id\": wid,\n",
    "            \"page\": current_page,\n",
    "            \"limit\": batch_size\n",
    "        }\n",
    "\n",
    "        query_string = urlencode(params)\n",
    "        full_url = f\"{base_url}?{query_string}\"\n",
    "        \n",
    "        r = requests.get(full_url, auth=(api_user, api_password))\n",
    "        # r = requests.get(f\"https://api.tapd.cn/tapd_wikis?workspace_id={workspace_id}\", auth=(api_user, api_password))\n",
    "        ret = r.text # 获取接口返回结果\n",
    "        decoded_data = json.loads(ret)\n",
    "        if(decoded_data['status'] != 1):\n",
    "            mylogger.error(decoded_data)\n",
    "            break\n",
    "        else:\n",
    "            story_entries = decoded_data[\"data\"]\n",
    "            #mylogger.debug(f\"number of wiki pages are {len(story_entries)}\")\n",
    "            index = 1\n",
    "            for entry in story_entries:\n",
    "                story = entry[\"Story\"]\n",
    "                item_to_analyze.append(story)\n",
    "                result = local_session.query(Story).filter(Story.story_id == story['id']).first()\n",
    "                # sql = f\"SELECT story_id, finger_print FROM {story_table} WHERE story_id=%s\"\n",
    "                # execute_query(sql, (story[\"id\"],))\n",
    "                # results = db_cursor.fetchone()            \n",
    "                if result:\n",
    "                    ID = result.story_id\n",
    "                    finger_print =result.finger_print    \n",
    "                    sha_digest = generate_sha_digest(html_to_text(story[\"description\"]))\n",
    "                    if finger_print == sha_digest:\n",
    "                        #mylogger.debug(f\"story {ID} already exist, content is the same\")\n",
    "                        pass\n",
    "                    else:\n",
    "                        #mylogger.debug(f\"story {ID} already exist, but content is different\")  \n",
    "                        item_to_analyze.append(story)             \n",
    "                        current_batch.append(story)\n",
    "                else:\n",
    "                    #mylogger.info(f\"{story['id']} {story['name']} should be added\")\n",
    "                    item_to_update.append(story)   \n",
    "                    current_batch.append(story)\n",
    "            current_index += batch_size\n",
    "            current_page += 1\n",
    "            page_to_break += 1\n",
    "            # if current_page >= 2:\n",
    "            #     break\n",
    "            time.sleep(1)\n",
    "            if current_page % 10 == 0:\n",
    "                time.sleep(20)  \n",
    "\n",
    "    update_story_db(current_batch)\n",
    "    complete_wid.add(wid)  \n",
    "    i += 1\n",
    "    time.sleep(5) \n",
    "                 \n",
    "mylogger.debug(f'total entries = {sum}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 501/35150 [01:30<1:44:18,  5.54it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(arr)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(arr, total\u001b[38;5;241m=\u001b[39mtotal):\n\u001b[1;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m local_session\u001b[38;5;241m.\u001b[39mquery(Story)\u001b[38;5;241m.\u001b[39mfilter(Story\u001b[38;5;241m.\u001b[39mvector_id \u001b[38;5;241m==\u001b[39m i)\u001b[38;5;241m.\u001b[39mfirst()\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\sqlalchemy\\orm\\query.py:2819\u001b[0m, in \u001b[0;36mQuery.first\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter()\u001b[38;5;241m.\u001b[39mfirst()\n\u001b[0;32m   2818\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39m_iter()\u001b[38;5;241m.\u001b[39mfirst()\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\sqlalchemy\\orm\\query.py:2903\u001b[0m, in \u001b[0;36mQuery._iter\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2900\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params\n\u001b[0;32m   2902\u001b[0m statement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_statement_20()\n\u001b[1;32m-> 2903\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   2904\u001b[0m     statement,\n\u001b[0;32m   2905\u001b[0m     params,\n\u001b[0;32m   2906\u001b[0m     execution_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sa_orm_load_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_options},\n\u001b[0;32m   2907\u001b[0m )\n\u001b[0;32m   2909\u001b[0m \u001b[38;5;66;03m# legacy: automatically set scalars, unique\u001b[39;00m\n\u001b[0;32m   2910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_attributes\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_single_entity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:1712\u001b[0m, in \u001b[0;36mSession.execute\u001b[1;34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, **kw)\u001b[0m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1711\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_for_bind(bind)\n\u001b[1;32m-> 1712\u001b[0m result \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39m_execute_20(statement, params \u001b[38;5;129;01mor\u001b[39;00m {}, execution_options)\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compile_state_cls:\n\u001b[0;32m   1715\u001b[0m     result \u001b[38;5;241m=\u001b[39m compile_state_cls\u001b[38;5;241m.\u001b[39morm_setup_cursor_result(\n\u001b[0;32m   1716\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1717\u001b[0m         statement,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m         result,\n\u001b[0;32m   1722\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1631\u001b[0m, in \u001b[0;36mConnection._execute_20\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1627\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[0;32m   1628\u001b[0m         exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[38;5;241m=\u001b[39merr\n\u001b[0;32m   1629\u001b[0m     )\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\u001b[38;5;28mself\u001b[39m, args_10style, kwargs_10style, execution_options)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:332\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_on_connection\u001b[39m(\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    330\u001b[0m ):\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_execution:\n\u001b[1;32m--> 332\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m connection\u001b[38;5;241m.\u001b[39m_execute_clauseelement(\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;28mself\u001b[39m, multiparams, params, execution_options\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1498\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[0;32m   1486\u001b[0m compiled_cache \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1487\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1488\u001b[0m )\n\u001b[0;32m   1490\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1491\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1492\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1497\u001b[0m )\n\u001b[1;32m-> 1498\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_context(\n\u001b[0;32m   1499\u001b[0m     dialect,\n\u001b[0;32m   1500\u001b[0m     dialect\u001b[38;5;241m.\u001b[39mexecution_ctx_cls\u001b[38;5;241m.\u001b[39m_init_compiled,\n\u001b[0;32m   1501\u001b[0m     compiled_sql,\n\u001b[0;32m   1502\u001b[0m     distilled_params,\n\u001b[0;32m   1503\u001b[0m     execution_options,\n\u001b[0;32m   1504\u001b[0m     compiled_sql,\n\u001b[0;32m   1505\u001b[0m     distilled_params,\n\u001b[0;32m   1506\u001b[0m     elem,\n\u001b[0;32m   1507\u001b[0m     extracted_params,\n\u001b[0;32m   1508\u001b[0m     cache_hit\u001b[38;5;241m=\u001b[39mcache_hit,\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1512\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1513\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1517\u001b[0m         ret,\n\u001b[0;32m   1518\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1859\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[0;32m   1863\u001b[0m         e, statement, parameters, cursor, context\n\u001b[0;32m   1864\u001b[0m     )\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2047\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2043\u001b[0m         util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[0;32m   2044\u001b[0m             sqlalchemy_exception, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me\n\u001b[0;32m   2045\u001b[0m         )\n\u001b[0;32m   2046\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2047\u001b[0m         util\u001b[38;5;241m.\u001b[39mraise_(exc_info[\u001b[38;5;241m1\u001b[39m], with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1817\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[0;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[0;32m   1821\u001b[0m         )\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1826\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1830\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1831\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\pymysql\\cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    151\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmogrify(query, args)\n\u001b[1;32m--> 153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query(query)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\pymysql\\cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    320\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_result()\n\u001b[1;32m--> 322\u001b[0m conn\u001b[38;5;241m.\u001b[39mquery(q)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_result()\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\pymysql\\connections.py:558\u001b[0m, in \u001b[0;36mConnection.query\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    556\u001b[0m     sql \u001b[38;5;241m=\u001b[39m sql\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_command(COMMAND\u001b[38;5;241m.\u001b[39mCOM_QUERY, sql)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_query_result(unbuffered\u001b[38;5;241m=\u001b[39munbuffered)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\pymysql\\connections.py:822\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    821\u001b[0m     result \u001b[38;5;241m=\u001b[39m MySQLResult(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 822\u001b[0m     result\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mserver_status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\pymysql\\connections.py:1200\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1200\u001b[0m         first_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_read_packet()\n\u001b[0;32m   1202\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m first_packet\u001b[38;5;241m.\u001b[39mis_ok_packet():\n\u001b[0;32m   1203\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_ok_packet(first_packet)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\pymysql\\connections.py:739\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    737\u001b[0m buff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m()\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 739\u001b[0m     packet_header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_bytes(\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;66;03m# if DEBUG: dump_packet(packet_header)\u001b[39;00m\n\u001b[0;32m    742\u001b[0m     btrl, btrh, packet_number \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<HBB\u001b[39m\u001b[38;5;124m\"\u001b[39m, packet_header)\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\site-packages\\pymysql\\connections.py:779\u001b[0m, in \u001b[0;36mConnection._read_bytes\u001b[1;34m(self, num_bytes)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 779\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rfile\u001b[38;5;241m.\u001b[39mread(num_bytes)\n\u001b[0;32m    780\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Anaconda3\\Anaconda\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "missing = []\n",
    "arr = list(range(35150))\n",
    "total = len(arr)\n",
    "for i in tqdm(arr, total=total):\n",
    "    result = local_session.query(Story).filter(Story.vector_id == i).first()\n",
    "    if result:\n",
    "        continue\n",
    "    else:\n",
    "        #print(f'missing i')\n",
    "        missing.append(i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate vector IDs found.\n",
      "1651\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "vector_ids = local_session.query(Story.vector_id).filter(Story.vector_id != None).all()\n",
    "unique_vector_ids = set([id[0] for id in vector_ids])\n",
    "if len(vector_ids) == len(unique_vector_ids):\n",
    "    print(\"No duplicate vector IDs found.\")\n",
    "else:\n",
    "    print(\"Duplicate vector IDs found.\")\n",
    "\n",
    "arr = set(range(35150))\n",
    "difference = arr.difference(unique_vector_ids)\n",
    "print(len(difference))\n",
    "print(len(vector_ids) - len(unique_vector_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下任务在server上运行，作废"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-26 10:03:50.042\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mto process: 908, size of FAISS: 17673\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm \n",
    "\n",
    "if isBP():\n",
    "    #total_stories = local_session.query(BPStory).filter(BPStory.vector_id == None).all()\n",
    "    total_stories = local_session.query(BPStory).filter(BPStory.vector_id == None).order_by(BPStory.id.asc()).all()\n",
    "    index = faiss.read_index(\"bp_story.faiss\")\n",
    "    # index = faiss.IndexFlatL2(1024)\n",
    "else:\n",
    "    total_stories = local_session.query(Story).filter(Story.vector_id == None).all()\n",
    "    index = faiss.read_index(\"../story.faiss\")\n",
    "    \n",
    "length = len(total_stories)\n",
    "mylogger.debug(f'to process: {len(total_stories)}, size of FAISS: {index.ntotal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 908/908 [17:45<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "first_file_flg = True\n",
    "for story in tqdm(total_stories,total=length):  \n",
    "    if story.vector_id is None or story.vector_id == '':  # 检查vector_id是否为空字符串或None  \n",
    "        # mylogger.debug(f\"Start to process {index.ntotal}/{len(local_session.query(Story).all())}\")\n",
    "        if isBP():\n",
    "            content = story.name\n",
    "        else:\n",
    "            content = '标题：' + story.name + \"\\n\" + '内容：' + story.content\n",
    "        vec = create_embedding_bge(content)\n",
    "        story.vector_id = index.ntotal\n",
    "        index.add(np.array([vec]))    \n",
    "        local_session.add(story)  # 将更新后的故事添加回session，这样更改才会被保存到数据库中    \n",
    "        \n",
    "    if index.ntotal%25 == 0:\n",
    "        if isBP():\n",
    "            file_name = f'bp_story_{index.ntotal}.faiss'\n",
    "        else:\n",
    "            file_name = f'story_{index.ntotal}.faiss'\n",
    "        local_session.commit()\n",
    "        faiss.write_index(index, file_name)\n",
    "        \n",
    "        if first_file_flg:\n",
    "            first_file_flg = False\n",
    "        else:\n",
    "            os.remove(last_file_name)\n",
    "        last_file_name = file_name  \n",
    "            \n",
    "local_session.commit()\n",
    "if isBP():\n",
    "    faiss.write_index(index, \"bp_story.faiss\")\n",
    "else:\n",
    "    faiss.write_index(index, \"story.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18581"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_index = faiss.read_index('bp_story.faiss')\n",
    "story_index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_page = 1\n",
    "base_url = \"https://api.tapd.cn/stories\"\n",
    "if total_entries >= 1000:\n",
    "    batch_size = 200\n",
    "else:\n",
    "    batch_size =100\n",
    "current_index = 0\n",
    "item_number = 0\n",
    "item_list_original = []\n",
    "item_to_update = []\n",
    "item_to_analyze = []\n",
    "\n",
    "\n",
    "while current_index < total_entries:\n",
    "    mylogger.debug(f\">>>>>>>>>>Fetch page #{current_page}\")\n",
    "    params = {\n",
    "        \"workspace_id\": workspace_id,\n",
    "        \"page\": current_page,\n",
    "        \"limit\": batch_size\n",
    "    }\n",
    "\n",
    "    query_string = urlencode(params)\n",
    "    full_url = f\"{base_url}?{query_string}\"\n",
    "    \n",
    "    r = requests.get(full_url, auth=(api_user, api_password))\n",
    "    # r = requests.get(f\"https://api.tapd.cn/tapd_wikis?workspace_id={workspace_id}\", auth=(api_user, api_password))\n",
    "    ret = r.text # 获取接口返回结果\n",
    "    decoded_data = json.loads(ret)\n",
    "    if(decoded_data['status'] != 1):\n",
    "        mylogger.error(decoded_data)\n",
    "        break\n",
    "    else:\n",
    "        story_entries = decoded_data[\"data\"]\n",
    "        mylogger.debug(f\"number of wiki pages are {len(story_entries)}\")\n",
    "        index = 1\n",
    "        for entry in story_entries:\n",
    "            story = entry[\"Story\"]\n",
    "            item_to_analyze.append(story)\n",
    "            sql = f\"SELECT story_id, finger_print FROM {story_table} WHERE story_id=%s\"\n",
    "            execute_query(sql, (story[\"id\"],))\n",
    "            results = db_cursor.fetchone()            \n",
    "            if results:\n",
    "                ID, finger_print = results                \n",
    "                sha_digest = generate_sha_digest(html_to_text(story[\"description\"]))\n",
    "                if finger_print == sha_digest:\n",
    "                    #mylogger.debug(f\"story {ID} already exist, content is the same\")\n",
    "                    pass\n",
    "                else:\n",
    "                    #mylogger.debug(f\"story {ID} already exist, but content is different\")  \n",
    "                    item_to_analyze.append(story)             \n",
    "            else:\n",
    "                #mylogger.info(f\"{story['id']} {story['name']} should be added\")\n",
    "                item_to_update.append(story)   \n",
    "        current_index += batch_size\n",
    "        current_page += 1\n",
    "        # if current_page >= 2:\n",
    "        #     break\n",
    "        time.sleep(1)\n",
    "        if current_page % 10 == 0:\n",
    "            time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":1,\"data\":{\"count\":17688},\"info\":\"success\"}\n",
      "\u001b[32m2024-01-23 19:00:25.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m17688\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "workspace_id = '62366085'\n",
    "project_name = {'55368532':'湖北交投司库',\n",
    "        '41574258':'产品研发',\n",
    "        '31121576':'蔚来汽车司库',\n",
    "        '50719964':'中国有色司库',\n",
    "        '37502023':'中建科司库', \n",
    "        '46779253':'陕投司库',\n",
    "        '49978871':'东风司库',\n",
    "        '56370180':'山子高科G20',\n",
    "        '65731238':'正浩创新G20',\n",
    "        '52867360':'坚果投影G20',\n",
    "        '42614505':'瑞派宠物医院G20',\n",
    "        '30386009':'深信服G20',\n",
    "        '54830814':'九号公司G20',\n",
    "        '62366085':'BP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-20 17:57:21.253\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[34m\u001b[1m详细方案见附件\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mylogger.debug(html_to_text(item_to_analyze[0]['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15221 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "total = len(item_to_update)\n",
    "\n",
    "for story in tqdm(item_to_update, total=total):\n",
    "    if story['workspace_id'] not in complete_wid:\n",
    "        continue\n",
    "    record = {}\n",
    "    record['workspace_id'] = story['workspace_id']\n",
    "    record['story_id'] = story['id']\n",
    "    record['name'] = story['name']\n",
    "    record['creator'] = story['creator']\n",
    "    record['status'] = story['status']\n",
    "    record['developer'] = story['developer']\n",
    "    if story['description']: \n",
    "        record['description'] = story['description'][:3000] \n",
    "    else: \n",
    "        record['description'] = ''\n",
    "    record['url'] = f\"https://www.tapd.cn/{workspace_id}/prong/stories/view/{record['story_id']}\"\n",
    "    record['content'] = html_to_text(record['description'])\n",
    "    record['finger_print'] = generate_sha_digest(record['content'])\n",
    "    record['modify_time'] = story['modified']\n",
    "    if story['completed']:\n",
    "        record['close_time'] = story['completed']\n",
    "    else:\n",
    "        record['close_time'] = '2100-01-01'\n",
    "    \n",
    "    if isBP():        \n",
    "        record['customer'] = story['custom_field_one']\n",
    "    \n",
    "    insert_data(local_session, record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if isBP():\n",
    "    story_index = faiss.read_index('bp_story.faiss')\n",
    "else:\n",
    "    story_index = faiss.read_index('story.faiss')\n",
    "\n",
    "def query(question, limit=10):\n",
    "    query_vec = create_embedding_bge(question)\n",
    "    distances, indices = story_index.search(np.array([query_vec], dtype=np.float32), limit)\n",
    "\n",
    "    results = []\n",
    "    for i in range(limit):\n",
    "        index = indices[0][i]\n",
    "        distance = distances[0][i]      \n",
    "        if isBP():\n",
    "            query_condition = BPStory.vector_id == index               \n",
    "            res = local_session.query(BPStory).filter(query_condition).all()  \n",
    "        else:\n",
    "            query_condition = Story.vector_id == index           \n",
    "            res = local_session.query(Story).filter(query_condition).all()          \n",
    "        \n",
    "        mylogger.debug(f\"Result {i + 1}> Distance:{distance}, index:{index}, Content:{res[0].name}\")      \n",
    "        results.append(res[0])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17673"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question ='功能是在预算模块增加多个预算组，有类似的功能实现吗？'\n",
    "question = '麻烦解释一下招商银行历史余额查询交易'\n",
    "results = query(question)\n",
    "\n",
    "for idx, result in enumerate(results, start=1):\n",
    "    res_str = f'[{idx}] project: {project_name[result.workspace_id]}'\n",
    "    res_str += f'; creator：{result.creator}'\n",
    "    res_str += f'; subject: {result.name}'\n",
    "    if isBP():\n",
    "        res_str += f'\\nmtime: {result.modify_time}, ctime: {result.close_time}, customer: {result.customer}'\n",
    "    else:\n",
    "        res_str += f'\\n content: {result.content}'    \n",
    "    res_str += f'\\n URL: {result.url}\\n'\n",
    "    res_str += f'-'*60\n",
    "    mylogger.debug(res_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'http://localhost:5003/query'\n",
    "input_string = '付款模块支付单可以修改付方账号'\n",
    "response = requests.post(url, json={'input_string': input_string}) \n",
    "mylogger.debug(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

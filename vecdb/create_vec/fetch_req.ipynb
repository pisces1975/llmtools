{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from urllib.parse import urlencode\n",
    "from utilities import logger\n",
    "import mysql.connector\n",
    "#from utilities import ConfigReader\n",
    "from utilities.sha_tools import generate_sha_digest\n",
    "from sqlalchemy import Column, Integer, String, Text, Date\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "api_user = 'h=Czxr?m'\n",
    "\n",
    "api_password = 'B537AF1C-64F9-FB2D-DC31-1E8C334E8D79'\n",
    "mylogger = logger.Logger(name='TAPD_ana', debug=True).logger\n",
    "\n",
    "def html_to_text(html):\n",
    "    if not html or len(html) == 0:\n",
    "        return ''\n",
    "    \n",
    "    #\"抛弃HTML标签，只提取所有文本内容\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-03 20:16:20.589\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[34m\u001b[1mDatabase connection successful. Result: 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 创建基础类\n",
    "Base = declarative_base()\n",
    "\n",
    "username = 'root'\n",
    "password = 'newpass'\n",
    "#host = \"127.0.0.1\"\n",
    "host = '10.101.9.50'\n",
    "dbname = 'requirements'\n",
    "engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}/{dbname}\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "local_session = Session()\n",
    "\n",
    "try:\n",
    "    # 连接数据库，并执行一个简单查询\n",
    "    connection = engine.connect()\n",
    "    result = connection.execute(\"SELECT 1\")\n",
    "    \n",
    "    # 打印结果\n",
    "    mylogger.debug(f\"Database connection successful. Result: {result.scalar()}\")\n",
    "    \n",
    "    # 不要忘记关闭连接！\n",
    "    connection.close()\n",
    "    \n",
    "except Exception as e:\n",
    "    mylogger.error(f\"Database connection failed. Error: {e}\")\n",
    "\n",
    "class Project(Base):\n",
    "    __tablename__ = 'project_info'\n",
    "\n",
    "    workspace_id = Column(String(255), primary_key=True)\n",
    "    name = Column(String(255))\n",
    "    systems = Column(String(255))\n",
    "    modify_time = Column(Date)\n",
    "    extension1 = Column(String(255))\n",
    "    url = Column(String(255))\n",
    "    \n",
    "class BaseStory(Base):\n",
    "    __tablename__ = 'base_stories'\n",
    "    __abstract__ = True\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    workspace_id = Column(String(255))\n",
    "    story_id = Column(String(255))\n",
    "    name = Column(String(512))\n",
    "    description = Column(Text)\n",
    "    url = Column(String(255))\n",
    "    status = Column(String(255))\n",
    "    developer = Column(String(255))\n",
    "    creator = Column(String(255))\n",
    "    finger_print = Column(String(255))\n",
    "    extension1 = Column(String(255))\n",
    "    extension2 = Column(String(255))\n",
    "    extension3 = Column(String(255))\n",
    "    extension4 = Column(String(255))\n",
    "    content = Column(Text)\n",
    "    vector_id = Column(Integer)\n",
    "    modify_time = Column(Date)\n",
    "    close_time = Column(Date)\n",
    "class Story(BaseStory):\n",
    "    __tablename__ = 'stories'    \n",
    "\n",
    "\n",
    "class BPStory(BaseStory):\n",
    "    __tablename__ = 'stories_bp' \n",
    "    customer = Column(String(255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add admin info to project info db, no longer used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "data = pd.read_excel('project-0129.xlsx')\n",
    "\n",
    "# admin info is added in \"项目信息.xlsx\"，this function is not longer used\n",
    "def update_admin():\n",
    "        for _, row in data.iterrows():\n",
    "                project_record = local_session.query(Project).filter_by(workspace_id=row['workspace_id']).first()\n",
    "\n",
    "                # 更新extension字段\n",
    "                if project_record:\n",
    "                        project_record.extension1 = row['管理员']\n",
    "                        local_session.commit()\n",
    "                        print(f\"Record with workspace_id '{project_record.workspace_id}' updated successfully.\")\n",
    "                else:\n",
    "                        print(f\"Record with workspace_id 'your_workspace_id' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add new projects to project db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-03 20:19:05.801\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 贵州能源（盘江）\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:05.826\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 海马财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:05.844\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 湖南高速\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:05.862\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 华菱财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:05.890\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 青建财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:05.908\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 中国有色 - 财司\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:05.927\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 九州通\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:05.955\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 浙能财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:05.971\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 河南能源 - 财司\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:05.988\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 万向财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.006\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 江西交投\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.023\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 悦达财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.041\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 浙交投财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.060\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 凤凰出版\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.077\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 甘电投\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.095\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 伊泰财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.112\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 包钢财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.129\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 传化财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.147\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 一重财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.169\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 杭州锦江\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.187\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 金川财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.205\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 亿利财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.222\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 新华联财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.241\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 三环财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.260\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 中旅财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.277\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 天津港财务\u001b[0m\n",
      "\u001b[32m2024-04-03 20:19:06.295\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mneed to add project 正泰财务\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#from sqlalchemy import create_engine, Table, MetaData\n",
    "#from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "current_date = current_datetime.date()\n",
    "\n",
    "# 使用pandas读取excel文件\n",
    "#data = pd.read_excel('项目信息.xls')\n",
    "data = pd.read_excel('project-0129.xlsx')\n",
    "\n",
    "execute_add_flag = True\n",
    "\n",
    "# 遍历数据行并插入到数据库表中\n",
    "for _, row in data.iterrows():\n",
    "    if not local_session.query(Project).filter_by(workspace_id=row['workspace_id']).first():  \n",
    "        mylogger.debug(f\"need to add project {row['name']}\")      \n",
    "        if execute_add_flag:\n",
    "                record={'workspace_id':row['workspace_id'], \n",
    "                        'name':row['name'], \n",
    "                        'systems':row['systems'], \n",
    "                        'modify_time':current_date, \n",
    "                        'url':f\"https://www.tapd.cn/{row['workspace_id']}\",\n",
    "                        'extension1':row['admin']}\n",
    "                project = Project(**record)\n",
    "                local_session.add(project)  \n",
    "\n",
    "# 提交会话\n",
    "if execute_add_flag:\n",
    "      local_session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-24 22:46:52.747\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[34m\u001b[1m5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 查询所有的workspace_id\n",
    "workspace_ids = local_session.query(Project.workspace_id).all()\n",
    "# 将结果转为列表\n",
    "workspace_id_list = [id[0] for id in workspace_ids]\n",
    "\n",
    "\n",
    "wid_already_in = local_session.query(Story.workspace_id).distinct().all()\n",
    "wid_already_in_list = [id[0] for id in wid_already_in]\n",
    "wid_already_in_list.append('62366085') # BP，单独存储\n",
    "wid_already_in_list.append('39451937') # 星票通，单独存储\n",
    "wid_already_in_list.append('54057645') #雅迪，没有需求\n",
    "new_ids = set(workspace_id_list).difference(set(wid_already_in_list))\n",
    "mylogger.debug(len(new_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_table = '../stories'\n",
    "def isBP():\n",
    "    if 'bp' in story_table:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "isBP()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加新项目时，修改stories DB的工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def insert_data(session, record):\n",
    "    story = None\n",
    "    if isBP():\n",
    "        if not session.query(BPStory).filter_by(story_id=record['story_id']).first():\n",
    "            story = BPStory(**record)\n",
    "    else:\n",
    "        if not session.query(Story).filter_by(story_id=record['story_id']).first():\n",
    "            story = Story(**record)\n",
    "    if story:\n",
    "        session.add(story)\n",
    "        session.commit()\n",
    "\n",
    "def update_story_db(items):\n",
    "    total = len(items)\n",
    "    for story in tqdm(items, total=total):\n",
    "        # if story['workspace_id'] not in complete_wid:\n",
    "        #     continue\n",
    "        record = {}\n",
    "        record['workspace_id'] = story['workspace_id']\n",
    "        record['story_id'] = story['id']\n",
    "        record['name'] = story['name']\n",
    "        record['creator'] = story['creator']\n",
    "        record['status'] = story['status']\n",
    "        record['developer'] = story['developer']\n",
    "        if story['description']: \n",
    "            record['description'] = story['description'][:3000] \n",
    "        else: \n",
    "            record['description'] = ''\n",
    "        record['url'] = f\"https://www.tapd.cn/{record['workspace_id']}/prong/stories/view/{record['story_id']}\"\n",
    "        record['content'] = html_to_text(record['description'])\n",
    "        record['finger_print'] = generate_sha_digest(record['content'])\n",
    "        record['modify_time'] = story['modified']\n",
    "        if story['completed']:\n",
    "            record['close_time'] = story['completed']\n",
    "        else:\n",
    "            record['close_time'] = '2100-01-01'\n",
    "        \n",
    "        if isBP():        \n",
    "            record['customer'] = story['custom_field_one']\n",
    "        \n",
    "        insert_data(local_session, record)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新现有项目时，修改stories DB的工具函数。0401 修改为fetch_req_server.py，运行在server上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def insert_or_update_data(session, record):\n",
    "    if isBP():\n",
    "        # 查询是否存在 story_id 相同的 BPStory 记录\n",
    "        existing_story = session.query(BPStory).filter_by(story_id=record['story_id']).first()\n",
    "        if existing_story:\n",
    "            # 更新已有记录\n",
    "            record['extension1'] = 'UPDATE'\n",
    "            for key, value in record.items():\n",
    "                setattr(existing_story, key, value)\n",
    "        else:\n",
    "            # 创建新的 BPStory 记录\n",
    "            record['extension1'] = 'ADD'\n",
    "            existing_story = BPStory(**record)\n",
    "    else:\n",
    "        # 查询是否存在 story_id 相同的 Story 记录\n",
    "        existing_story = session.query(Story).filter_by(story_id=record['story_id']).first()\n",
    "        if existing_story:\n",
    "            # 更新已有记录\n",
    "            record['extension1'] = 'UPDATE'\n",
    "            for key, value in record.items():\n",
    "                setattr(existing_story, key, value)\n",
    "        else:\n",
    "            # 创建新的 Story 记录\n",
    "            record['extension1'] = 'ADD'\n",
    "            existing_story = Story(**record)\n",
    "\n",
    "    # 添加（或更新后相当于添加）记录到 session，并提交事务\n",
    "    session.add(existing_story)\n",
    "    session.commit()\n",
    "\n",
    "def insert_or_update_story_db(items):\n",
    "    total = len(items)\n",
    "    for story in tqdm(items, total=total):\n",
    "        # if story['workspace_id'] not in complete_wid:\n",
    "        #     continue\n",
    "        record = {}\n",
    "        record['workspace_id'] = story['workspace_id']\n",
    "        record['story_id'] = story['id']\n",
    "        record['name'] = story['name']\n",
    "        record['creator'] = story['creator']\n",
    "        record['status'] = story['status']\n",
    "        record['developer'] = story['developer']\n",
    "        if story['description']: \n",
    "            record['description'] = story['description'][:3000] \n",
    "        else: \n",
    "            record['description'] = ''\n",
    "        record['url'] = f\"https://www.tapd.cn/{record['workspace_id']}/prong/stories/view/{record['story_id']}\"\n",
    "        record['content'] = html_to_text(record['description'])\n",
    "        record['finger_print'] = generate_sha_digest(record['content'])\n",
    "        record['modify_time'] = story['modified']\n",
    "        if story['completed']:\n",
    "            record['close_time'] = story['completed']\n",
    "        else:\n",
    "            record['close_time'] = '2100-01-01'\n",
    "        \n",
    "        if isBP():        \n",
    "            record['customer'] = story['custom_field_one']\n",
    "        \n",
    "        insert_or_update_data(local_session, record) \n",
    "\n",
    "def update_story_status(ids, status):\n",
    "    total = len(ids)\n",
    "    for story_id in tqdm(ids, total=total): \n",
    "        if isBP():\n",
    "            # 更新 BPStory 表中 story_id 对应记录的 extension1 字段\n",
    "            local_session.query(BPStory).filter_by(story_id=story_id).update({\"extension1\": status})\n",
    "        else:\n",
    "            # 更新 Story 表中 story_id 对应记录的 extension1 字段\n",
    "            local_session.query(Story).filter_by(story_id=story_id).update({\"extension1\": status})\n",
    "\n",
    "    # 提交事务\n",
    "    local_session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析project list，找到需要更新的ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-31 20:17:39.338\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[34m\u001b[1m60 projects to analyze, 30386009 ... 68853386\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result_query  = local_session.query(Project.workspace_id).filter(Project.modify_time < '2024-3-15')\n",
    "project_list = result_query.all()\n",
    "mylogger.debug(f\"{len(project_list)} projects to analyze, {project_list[0][0]} ... {project_list[-1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "sum = 0\n",
    "base_url = \"https://api.tapd.cn/stories\"\n",
    "page_to_break = 0\n",
    "item_list_original = []\n",
    "item_to_update = []\n",
    "item_to_analyze = []\n",
    "\n",
    "analyse_res = []\n",
    "complete_wid = set()\n",
    "i = 1\n",
    "\n",
    "for row in project_list:   \n",
    "    wid = row[0]\n",
    "    id_to_keep = []\n",
    "    id_to_add = []\n",
    "    id_to_update = []\n",
    "\n",
    "    if wid == '62366085' or wid == '39451937':\n",
    "        story_table = '../bp_stories'  \n",
    "        continue  \n",
    "    else:\n",
    "        story_table = '../stories'   \n",
    "\n",
    "    try:\n",
    "        r = requests.get(f\"https://api.tapd.cn/stories/count?workspace_id={wid}\", auth=(api_user, api_password))\n",
    "        ret = r.text # 获取接口返回结果\n",
    "        # print(ret) # Python 3\n",
    "        json_string = json.loads(ret)\n",
    "        total_entries = json_string['data']['count']\n",
    "        pinfo = local_session.query(Project.name).filter(Project.workspace_id == wid).first()\n",
    "        prj_name = pinfo[0]\n",
    "        # mylogger.info(f'{wid} {prj_name}, {total_entries}')\n",
    "        sum += total_entries\n",
    "    except Exception as e:\n",
    "        mylogger.error(f\"{wid} {prj_name} Something goes wrong {e}\")    \n",
    "        continue\n",
    "\n",
    "    current_page = 1    \n",
    "    if total_entries >= 1000:\n",
    "        batch_size = 200\n",
    "    else:\n",
    "        batch_size =100\n",
    "    current_index = 0\n",
    "    item_number = 0    \n",
    "\n",
    "    current_batch = []\n",
    "    mylogger.debug(f\"{i}/{len(project_list)} Start to process {wid} {prj_name} {total_entries} entries\")\n",
    "    while current_index < total_entries:\n",
    "        mylogger.debug(f\">>>>>>>>>>Fetch page #{current_page}\")\n",
    "        params = {\n",
    "            \"workspace_id\": wid,\n",
    "            \"page\": current_page,\n",
    "            \"limit\": batch_size\n",
    "        }\n",
    "\n",
    "        query_string = urlencode(params)\n",
    "        full_url = f\"{base_url}?{query_string}\"\n",
    "        \n",
    "        r = requests.get(full_url, auth=(api_user, api_password))\n",
    "        # r = requests.get(f\"https://api.tapd.cn/tapd_wikis?workspace_id={workspace_id}\", auth=(api_user, api_password))\n",
    "        ret = r.text # 获取接口返回结果\n",
    "        decoded_data = json.loads(ret)\n",
    "        if(decoded_data['status'] != 1):\n",
    "            mylogger.error(decoded_data)\n",
    "            break\n",
    "        else:\n",
    "            story_entries = decoded_data[\"data\"]\n",
    "            #mylogger.debug(f\"number of wiki pages are {len(story_entries)}\")\n",
    "            index = 1\n",
    "            for entry in story_entries:\n",
    "                story = entry[\"Story\"]\n",
    "                item_to_analyze.append(story)\n",
    "                result = local_session.query(Story).filter(Story.story_id == story['id']).first()\n",
    "                if result:\n",
    "                    ID = result.story_id\n",
    "                    finger_print =result.finger_print    \n",
    "                    sha_digest = generate_sha_digest(html_to_text(story[\"description\"]))\n",
    "                    if finger_print == sha_digest:\n",
    "                        #mylogger.debug(f\"story {ID} already exist, content is the same\")\n",
    "                        id_to_keep.append(ID)\n",
    "                        pass\n",
    "                    else:\n",
    "                        #mylogger.debug(f\"story {ID} already exist, but content is different\")  \n",
    "                        item_to_analyze.append(story)             \n",
    "                        id_to_update.append(ID)\n",
    "                        current_batch.append(story)\n",
    "                else:\n",
    "                    #mylogger.info(f\"{story['id']} {story['name']} should be added\")\n",
    "                    item_to_update.append(story)   \n",
    "                    current_batch.append(story)\n",
    "                    id_to_add.append(story['id'])\n",
    "\n",
    "            current_index += batch_size\n",
    "            current_page += 1\n",
    "            page_to_break += 1\n",
    "            # if current_page >= 2:\n",
    "            #     break\n",
    "            time.sleep(1)\n",
    "            if current_page % 10 == 0:\n",
    "                time.sleep(20)  \n",
    "\n",
    "    insert_or_update_story_db(current_batch)\n",
    "    mylogger.debug(f\"{wid} {prj_name}, {len(id_to_keep)} keep,  {len(id_to_add)} add, {len(id_to_update)} update\")\n",
    "    analyse_res.append({\n",
    "        'wid':wid,\n",
    "        'project':prj_name,\n",
    "        'keep':id_to_keep,\n",
    "        'add':id_to_add,\n",
    "        'update':id_to_update\n",
    "    })\n",
    "    update_story_status(id_to_keep,'KEEP')    \n",
    "    local_session.query(Project).filter_by(workspace_id=wid).update({\"modify_time\": datetime.now()})\n",
    "    #complete_wid.add(wid)  \n",
    "    i += 1\n",
    "    time.sleep(5) \n",
    "                 \n",
    "mylogger.debug(f'total entries = {sum}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(analyse_res, start=1):\n",
    "    mylogger.debug(f\"{idx}/{len(analyse_res)}. {item['wid']}-{item['project']}, {len(item['keep'])} keep, {len(item['add'])} add, {len(item['update'])} update\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加新的Project，把Project放到new_ids就可以了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-24 23:05:22.300\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[34m\u001b[1m1/1 Start to process 66563110 国家电投 3335 entries\u001b[0m\n",
      "\u001b[32m2024-03-24 23:05:22.302\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #1\u001b[0m\n",
      "\u001b[32m2024-03-24 23:06:03.344\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #2\u001b[0m\n",
      "\u001b[32m2024-03-24 23:06:42.618\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #3\u001b[0m\n",
      "\u001b[32m2024-03-24 23:07:22.087\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #4\u001b[0m\n",
      "\u001b[32m2024-03-24 23:08:01.914\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #5\u001b[0m\n",
      "\u001b[32m2024-03-24 23:08:41.161\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #6\u001b[0m\n",
      "\u001b[32m2024-03-24 23:09:20.925\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #7\u001b[0m\n",
      "\u001b[32m2024-03-24 23:10:01.632\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #8\u001b[0m\n",
      "\u001b[32m2024-03-24 23:10:42.874\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #9\u001b[0m\n",
      "\u001b[32m2024-03-24 23:11:43.219\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #10\u001b[0m\n",
      "\u001b[32m2024-03-24 23:12:23.350\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #11\u001b[0m\n",
      "\u001b[32m2024-03-24 23:13:03.212\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #12\u001b[0m\n",
      "\u001b[32m2024-03-24 23:13:43.427\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #13\u001b[0m\n",
      "\u001b[32m2024-03-24 23:14:23.137\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #14\u001b[0m\n",
      "\u001b[32m2024-03-24 23:15:03.275\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #15\u001b[0m\n",
      "\u001b[32m2024-03-24 23:15:43.276\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #16\u001b[0m\n",
      "\u001b[32m2024-03-24 23:16:24.900\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1m>>>>>>>>>>Fetch page #17\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2681/3335 [07:14<02:41,  4.05it/s]C:\\Users\\NstcUser\\AppData\\Local\\Temp\\ipykernel_16808\\1660417174.py:26: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html, \"html.parser\")\n",
      "100%|██████████| 3335/3335 [09:36<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-24 23:26:33.092\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m93\u001b[0m - \u001b[34m\u001b[1mtotal entries = 3335\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "base_url = \"https://api.tapd.cn/stories\"\n",
    "page_to_break = 0\n",
    "item_list_original = []\n",
    "item_to_update = []\n",
    "item_to_analyze = []\n",
    "complete_wid = set()\n",
    "i = 1\n",
    "\n",
    "for wid in new_ids:    \n",
    "    try:\n",
    "        r = requests.get(f\"https://api.tapd.cn/stories/count?workspace_id={wid}\", auth=(api_user, api_password))\n",
    "        ret = r.text # 获取接口返回结果\n",
    "        # print(ret) # Python 3\n",
    "        json_string = json.loads(ret)\n",
    "        total_entries = json_string['data']['count']\n",
    "        pinfo = local_session.query(Project.name).filter(Project.workspace_id == wid).first()\n",
    "        prj_name = pinfo[0]\n",
    "        # mylogger.info(f'{wid} {prj_name}, {total_entries}')\n",
    "        sum += total_entries\n",
    "    except Exception as e:\n",
    "        mylogger.error(f\"{wid} {prj_name} Something goes wrong {e}\")    \n",
    "        continue\n",
    "\n",
    "    current_page = 1    \n",
    "    if total_entries >= 1000:\n",
    "        batch_size = 200\n",
    "    else:\n",
    "        batch_size =100\n",
    "    current_index = 0\n",
    "    item_number = 0    \n",
    "\n",
    "    current_batch = []\n",
    "    mylogger.debug(f\"{i}/{len(new_ids)} Start to process {wid} {prj_name} {total_entries} entries\")\n",
    "    while current_index < total_entries:\n",
    "        mylogger.debug(f\">>>>>>>>>>Fetch page #{current_page}\")\n",
    "        params = {\n",
    "            \"workspace_id\": wid,\n",
    "            \"page\": current_page,\n",
    "            \"limit\": batch_size\n",
    "        }\n",
    "\n",
    "        query_string = urlencode(params)\n",
    "        full_url = f\"{base_url}?{query_string}\"\n",
    "        \n",
    "        r = requests.get(full_url, auth=(api_user, api_password))\n",
    "        # r = requests.get(f\"https://api.tapd.cn/tapd_wikis?workspace_id={workspace_id}\", auth=(api_user, api_password))\n",
    "        ret = r.text # 获取接口返回结果\n",
    "        decoded_data = json.loads(ret)\n",
    "        if(decoded_data['status'] != 1):\n",
    "            mylogger.error(decoded_data)\n",
    "            break\n",
    "        else:\n",
    "            story_entries = decoded_data[\"data\"]\n",
    "            #mylogger.debug(f\"number of wiki pages are {len(story_entries)}\")\n",
    "            index = 1\n",
    "            for entry in story_entries:\n",
    "                story = entry[\"Story\"]\n",
    "                item_to_analyze.append(story)\n",
    "                result = local_session.query(Story).filter(Story.story_id == story['id']).first()\n",
    "                # sql = f\"SELECT story_id, finger_print FROM {story_table} WHERE story_id=%s\"\n",
    "                # execute_query(sql, (story[\"id\"],))\n",
    "                # results = db_cursor.fetchone()            \n",
    "                if result:\n",
    "                    ID = result.story_id\n",
    "                    finger_print =result.finger_print    \n",
    "                    sha_digest = generate_sha_digest(html_to_text(story[\"description\"]))\n",
    "                    if finger_print == sha_digest:\n",
    "                        #mylogger.debug(f\"story {ID} already exist, content is the same\")\n",
    "                        pass\n",
    "                    else:\n",
    "                        #mylogger.debug(f\"story {ID} already exist, but content is different\")  \n",
    "                        item_to_analyze.append(story)             \n",
    "                        current_batch.append(story)\n",
    "                else:\n",
    "                    #mylogger.info(f\"{story['id']} {story['name']} should be added\")\n",
    "                    item_to_update.append(story)   \n",
    "                    current_batch.append(story)\n",
    "            current_index += batch_size\n",
    "            current_page += 1\n",
    "            page_to_break += 1\n",
    "            # if current_page >= 2:\n",
    "            #     break\n",
    "            time.sleep(1)\n",
    "            if current_page % 10 == 0:\n",
    "                time.sleep(20)  \n",
    "\n",
    "    update_story_db(current_batch)\n",
    "    complete_wid.add(wid)  \n",
    "    i += 1\n",
    "    time.sleep(5) \n",
    "                 \n",
    "mylogger.debug(f'total entries = {sum}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate vector IDs found.\n",
      "1651\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "vector_ids = local_session.query(Story.vector_id).filter(Story.vector_id != None).all()\n",
    "unique_vector_ids = set([id[0] for id in vector_ids])\n",
    "if len(vector_ids) == len(unique_vector_ids):\n",
    "    print(\"No duplicate vector IDs found.\")\n",
    "else:\n",
    "    print(\"Duplicate vector IDs found.\")\n",
    "\n",
    "arr = set(range(35150))\n",
    "difference = arr.difference(unique_vector_ids)\n",
    "print(len(difference))\n",
    "print(len(vector_ids) - len(unique_vector_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新现有项目时，根据extension1的值构建新的vector DB，注意BP不做update和delete，仅做ADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-01 16:43:20.147\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[34m\u001b[1mStart to connect xinference server at http://10.101.9.50:9998\u001b[0m\n",
      "\u001b[32m2024-04-01 16:43:40.789\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mSuccessfully connect mysql database\u001b[0m\n",
      "\u001b[32m2024-04-01 16:43:40.790\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m33\u001b[0m - \u001b[34m\u001b[1m{'host': '10.101.9.50', 'user': 'root', 'password': 'newpass', 'database': 'requirements'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from xinference.client import Client\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "x_addr = 'http://10.101.9.50:9998'\n",
    "mylogger.debug(f\"Start to connect xinference server at {x_addr}\")\n",
    "try:\n",
    "    client = Client(x_addr)    \n",
    "    model_uid = client.launch_model(model_name=\"bge-large-zh-v1.5\", model_type=\"embedding\")    \n",
    "    model = client.get_model(model_uid)\n",
    "except Exception as e:\n",
    "    mylogger.error(f\"Something goes wrong: {e}\")   \n",
    "def create_embedding_bge(sentence):\n",
    "    result = model.create_embedding(sentence)\n",
    "    embedding = result['data'][0]['embedding']\n",
    "    # LOG.debug(f\"length of embedding {len(embedding)}, {embedding[:5]}\")\n",
    "    return embedding\n",
    "\n",
    "import mysql.connector\n",
    "mysql_db_config = {\n",
    "    \"host\": \"10.101.9.50\",\n",
    "    \"user\": 'root',\n",
    "    \"password\": 'newpass',\n",
    "    \"database\": 'requirements'\n",
    "}\n",
    "\n",
    "db_connection = mysql.connector.connect(**mysql_db_config)\n",
    "db_cursor = db_connection.cursor()\n",
    "if db_connection.is_connected():\n",
    "    mylogger.debug(\"Successfully connect mysql database\")\n",
    "\n",
    "mylogger.debug(mysql_db_config)\n",
    "def execute_query(query, params=()):\n",
    "    db_cursor.execute(query, params)\n",
    "    if query.strip().startswith(\"SELECT\"):\n",
    "        pass\n",
    "    else:\n",
    "        db_connection.commit() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 更新BP FAISS和vector_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\repo\\\\llmtools\\\\vecdb\\\\create_vec'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1368/1368 [26:23<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "index_current = faiss.read_index('../bp_story.faiss')\n",
    "curr_pos = index_current.ntotal\n",
    "\n",
    "query = \"SELECT id, story_id, name FROM stories_bp WHERE extension1='ADD'\"\n",
    "execute_query(query)\n",
    "res = db_cursor.fetchall()\n",
    "for row in tqdm(res,total=len(res)):\n",
    "    id, story_id, name = row\n",
    "    vec = create_embedding_bge(name)\n",
    "    index_current.add(np.array([vec])) \n",
    "    query = \"UPDATE stories_bp SET extension1='DONE', vector_id=%s WHERE id=%s\"\n",
    "    execute_query(query,(curr_pos,id))\n",
    "    curr_pos = index_current.ntotal\n",
    "\n",
    "    if curr_pos%25 == 0:\n",
    "        faiss.write_index(index_current, f'tmp/bp_story_{curr_pos}.faiss')   \n",
    "\n",
    "faiss.write_index(index_current, '../bp_story_new.faiss')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 更新Project REQ FAISS DB and vector_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43029/43029 [39:10<00:00, 18.31it/s]   \n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT id, story_id, vector_id, extension1, name, content FROM stories'\n",
    "execute_query(query)\n",
    "res = db_cursor.fetchall()\n",
    "curr_index = faiss.read_index('../story.faiss')\n",
    "#new_index = faiss.IndexFlatL2(1024)\n",
    "new_index = faiss.read_index('tmp/story_41450.faiss')\n",
    "\n",
    "query = \"UPDATE stories SET extension1=%s, vector_id=%s WHERE id=%s\"\n",
    "for idx, row in tqdm(enumerate(res), total=len(res)):\n",
    "    id, story_id, vector_id, extension1, name, content = row\n",
    "    curr_pos = new_index.ntotal\n",
    "    tmp_str = extension1 + '-DONE'\n",
    "    if extension1 == 'KEEP':\n",
    "        vector_id = int(vector_id)        \n",
    "        vector_to_add = curr_index.reconstruct(vector_id)\n",
    "        vector_to_add = np.array(vector_to_add).reshape(1, -1)\n",
    "        new_index.add(vector_to_add)        \n",
    "        execute_query(query,(tmp_str,curr_pos,id))\n",
    "    elif extension1 == 'ADD' or extension1 == 'UPDATE':\n",
    "        content_to_vec = '标题：' + name + \"\\n\" + '内容：' + content \n",
    "        #curr_pos = new_index.ntotal\n",
    "        vec = create_embedding_bge(content_to_vec)\n",
    "        new_index.add(np.array([vec]))         \n",
    "        #query = \"UPDATE stories_bp SET extension1=%s, vector_id=%s WHERE id=%s\"\n",
    "        execute_query(query,(tmp_str,curr_pos,id))\n",
    "    else:        \n",
    "        #query = \"UPDATE stories_bp SET extension1=%s, vector_id=%s WHERE id=%s\"\n",
    "        #execute_query(query,(tmp_str,-1,id))\n",
    "        continue\n",
    "\n",
    "    if curr_pos%50 == 0:\n",
    "        faiss.write_index(new_index, f'tmp/story_{curr_pos}.faiss')   \n",
    "\n",
    "faiss.write_index(new_index, '../story_new.faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/809 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 809/809 [00:18<00:00, 44.81it/s]\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT id, story_id, vector_id, extension1, name, content FROM stories WHERE id>=1 and id<=809'\n",
    "execute_query(query)\n",
    "res = db_cursor.fetchall()\n",
    "for idx, row in tqdm(enumerate(res), total=len(res)):\n",
    "    id, story_id, vector_id, extension1, name, content = row\n",
    "    query = \"UPDATE stories SET vector_id=%s WHERE id=%s\"\n",
    "    execute_query(query, (idx, id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下任务在server上运行，作废"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-26 10:03:50.042\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mto process: 908, size of FAISS: 17673\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm \n",
    "\n",
    "if isBP():\n",
    "    #total_stories = local_session.query(BPStory).filter(BPStory.vector_id == None).all()\n",
    "    total_stories = local_session.query(BPStory).filter(BPStory.vector_id == None).order_by(BPStory.id.asc()).all()\n",
    "    index = faiss.read_index(\"bp_story.faiss\")\n",
    "    # index = faiss.IndexFlatL2(1024)\n",
    "else:\n",
    "    total_stories = local_session.query(Story).filter(Story.vector_id == None).all()\n",
    "    index = faiss.read_index(\"../story.faiss\")\n",
    "    \n",
    "length = len(total_stories)\n",
    "mylogger.debug(f'to process: {len(total_stories)}, size of FAISS: {index.ntotal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 908/908 [17:45<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "first_file_flg = True\n",
    "for story in tqdm(total_stories,total=length):  \n",
    "    if story.vector_id is None or story.vector_id == '':  # 检查vector_id是否为空字符串或None  \n",
    "        # mylogger.debug(f\"Start to process {index.ntotal}/{len(local_session.query(Story).all())}\")\n",
    "        if isBP():\n",
    "            content = story.name\n",
    "        else:\n",
    "            content = '标题：' + story.name + \"\\n\" + '内容：' + story.content\n",
    "        vec = create_embedding_bge(content)\n",
    "        story.vector_id = index.ntotal\n",
    "        index.add(np.array([vec]))    \n",
    "        local_session.add(story)  # 将更新后的故事添加回session，这样更改才会被保存到数据库中    \n",
    "        \n",
    "    if index.ntotal%25 == 0:\n",
    "        if isBP():\n",
    "            file_name = f'bp_story_{index.ntotal}.faiss'\n",
    "        else:\n",
    "            file_name = f'story_{index.ntotal}.faiss'\n",
    "        local_session.commit()\n",
    "        faiss.write_index(index, file_name)\n",
    "        \n",
    "        if first_file_flg:\n",
    "            first_file_flg = False\n",
    "        else:\n",
    "            os.remove(last_file_name)\n",
    "        last_file_name = file_name  \n",
    "            \n",
    "local_session.commit()\n",
    "if isBP():\n",
    "    faiss.write_index(index, \"bp_story.faiss\")\n",
    "else:\n",
    "    faiss.write_index(index, \"story.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41451"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_index = faiss.read_index('tmp/story_41450.faiss')\n",
    "story_index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_page = 1\n",
    "base_url = \"https://api.tapd.cn/stories\"\n",
    "if total_entries >= 1000:\n",
    "    batch_size = 200\n",
    "else:\n",
    "    batch_size =100\n",
    "current_index = 0\n",
    "item_number = 0\n",
    "item_list_original = []\n",
    "item_to_update = []\n",
    "item_to_analyze = []\n",
    "\n",
    "\n",
    "while current_index < total_entries:\n",
    "    mylogger.debug(f\">>>>>>>>>>Fetch page #{current_page}\")\n",
    "    params = {\n",
    "        \"workspace_id\": workspace_id,\n",
    "        \"page\": current_page,\n",
    "        \"limit\": batch_size\n",
    "    }\n",
    "\n",
    "    query_string = urlencode(params)\n",
    "    full_url = f\"{base_url}?{query_string}\"\n",
    "    \n",
    "    r = requests.get(full_url, auth=(api_user, api_password))\n",
    "    # r = requests.get(f\"https://api.tapd.cn/tapd_wikis?workspace_id={workspace_id}\", auth=(api_user, api_password))\n",
    "    ret = r.text # 获取接口返回结果\n",
    "    decoded_data = json.loads(ret)\n",
    "    if(decoded_data['status'] != 1):\n",
    "        mylogger.error(decoded_data)\n",
    "        break\n",
    "    else:\n",
    "        story_entries = decoded_data[\"data\"]\n",
    "        mylogger.debug(f\"number of wiki pages are {len(story_entries)}\")\n",
    "        index = 1\n",
    "        for entry in story_entries:\n",
    "            story = entry[\"Story\"]\n",
    "            item_to_analyze.append(story)\n",
    "            sql = f\"SELECT story_id, finger_print FROM {story_table} WHERE story_id=%s\"\n",
    "            execute_query(sql, (story[\"id\"],))\n",
    "            results = db_cursor.fetchone()            \n",
    "            if results:\n",
    "                ID, finger_print = results                \n",
    "                sha_digest = generate_sha_digest(html_to_text(story[\"description\"]))\n",
    "                if finger_print == sha_digest:\n",
    "                    #mylogger.debug(f\"story {ID} already exist, content is the same\")\n",
    "                    pass\n",
    "                else:\n",
    "                    #mylogger.debug(f\"story {ID} already exist, but content is different\")  \n",
    "                    item_to_analyze.append(story)             \n",
    "            else:\n",
    "                #mylogger.info(f\"{story['id']} {story['name']} should be added\")\n",
    "                item_to_update.append(story)   \n",
    "        current_index += batch_size\n",
    "        current_page += 1\n",
    "        # if current_page >= 2:\n",
    "        #     break\n",
    "        time.sleep(1)\n",
    "        if current_page % 10 == 0:\n",
    "            time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":1,\"data\":{\"count\":17688},\"info\":\"success\"}\n",
      "\u001b[32m2024-01-23 19:00:25.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1m17688\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "workspace_id = '62366085'\n",
    "project_name = {'55368532':'湖北交投司库',\n",
    "        '41574258':'产品研发',\n",
    "        '31121576':'蔚来汽车司库',\n",
    "        '50719964':'中国有色司库',\n",
    "        '37502023':'中建科司库', \n",
    "        '46779253':'陕投司库',\n",
    "        '49978871':'东风司库',\n",
    "        '56370180':'山子高科G20',\n",
    "        '65731238':'正浩创新G20',\n",
    "        '52867360':'坚果投影G20',\n",
    "        '42614505':'瑞派宠物医院G20',\n",
    "        '30386009':'深信服G20',\n",
    "        '54830814':'九号公司G20',\n",
    "        '62366085':'BP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-20 17:57:21.253\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[34m\u001b[1m详细方案见附件\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mylogger.debug(html_to_text(item_to_analyze[0]['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15221 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "total = len(item_to_update)\n",
    "\n",
    "for story in tqdm(item_to_update, total=total):\n",
    "    if story['workspace_id'] not in complete_wid:\n",
    "        continue\n",
    "    record = {}\n",
    "    record['workspace_id'] = story['workspace_id']\n",
    "    record['story_id'] = story['id']\n",
    "    record['name'] = story['name']\n",
    "    record['creator'] = story['creator']\n",
    "    record['status'] = story['status']\n",
    "    record['developer'] = story['developer']\n",
    "    if story['description']: \n",
    "        record['description'] = story['description'][:3000] \n",
    "    else: \n",
    "        record['description'] = ''\n",
    "    record['url'] = f\"https://www.tapd.cn/{workspace_id}/prong/stories/view/{record['story_id']}\"\n",
    "    record['content'] = html_to_text(record['description'])\n",
    "    record['finger_print'] = generate_sha_digest(record['content'])\n",
    "    record['modify_time'] = story['modified']\n",
    "    if story['completed']:\n",
    "        record['close_time'] = story['completed']\n",
    "    else:\n",
    "        record['close_time'] = '2100-01-01'\n",
    "    \n",
    "    if isBP():        \n",
    "        record['customer'] = story['custom_field_one']\n",
    "    \n",
    "    insert_data(local_session, record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if isBP():\n",
    "    story_index = faiss.read_index('bp_story.faiss')\n",
    "else:\n",
    "    story_index = faiss.read_index('story.faiss')\n",
    "\n",
    "def query(question, limit=10):\n",
    "    query_vec = create_embedding_bge(question)\n",
    "    distances, indices = story_index.search(np.array([query_vec], dtype=np.float32), limit)\n",
    "\n",
    "    results = []\n",
    "    for i in range(limit):\n",
    "        index = indices[0][i]\n",
    "        distance = distances[0][i]      \n",
    "        if isBP():\n",
    "            query_condition = BPStory.vector_id == index               \n",
    "            res = local_session.query(BPStory).filter(query_condition).all()  \n",
    "        else:\n",
    "            query_condition = Story.vector_id == index           \n",
    "            res = local_session.query(Story).filter(query_condition).all()          \n",
    "        \n",
    "        mylogger.debug(f\"Result {i + 1}> Distance:{distance}, index:{index}, Content:{res[0].name}\")      \n",
    "        results.append(res[0])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17673"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question ='功能是在预算模块增加多个预算组，有类似的功能实现吗？'\n",
    "question = '麻烦解释一下招商银行历史余额查询交易'\n",
    "results = query(question)\n",
    "\n",
    "for idx, result in enumerate(results, start=1):\n",
    "    res_str = f'[{idx}] project: {project_name[result.workspace_id]}'\n",
    "    res_str += f'; creator：{result.creator}'\n",
    "    res_str += f'; subject: {result.name}'\n",
    "    if isBP():\n",
    "        res_str += f'\\nmtime: {result.modify_time}, ctime: {result.close_time}, customer: {result.customer}'\n",
    "    else:\n",
    "        res_str += f'\\n content: {result.content}'    \n",
    "    res_str += f'\\n URL: {result.url}\\n'\n",
    "    res_str += f'-'*60\n",
    "    mylogger.debug(res_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'http://localhost:5003/query'\n",
    "input_string = '付款模块支付单可以修改付方账号'\n",
    "response = requests.post(url, json={'input_string': input_string}) \n",
    "mylogger.debug(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
